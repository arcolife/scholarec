#!/usr/bin/env python
# -*- coding: utf-8 -*- 

## This file is part of ScholaRec.
## A recommendation engine for Scholarly works.
## Copyright (C) 2014  Archit Sharma <archit.py@gmail.com>
##
## ScholaRec is free software: you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation, either version 3 of the License, or
## (at your option) any later version.
##
## ScholaRec is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.
##
## You should have received a copy of the GNU General Public License
## along with this program.  If not, see <http://www.gnu.org/licenses/>

""" This module tests the scholarec modules by
implementing requests to query arXiv API."""

## import general modules
import os
import sys
from urllib2 import \
    urlopen
import json
from pprint import \
    pprint, pformat

## Import dependencies specific to scholarec
import wikipedia
from scholarec.base.arxiv import DocumentArXiv
SOURCE_PATH = os.path.dirname(os.path.abspath(__file__)) + '/../'
sys.path.insert(0, SOURCE_PATH)

class QueryParse:
    ''' mathods to parse query '''    
    def __init__(self, query_xml, keyword_list):
        self.query_xml = query_xml
        self.entry_count = None
        self.data_dict = None
        self.keywords = keyword_list
        self.doc = None
        self.data_json = None
        
    def parse_data(self):
        """ parse extracted data into python dict format """
        self.doc = DocumentArXiv(self.query_xml)
        #self.data_xml, self.data_dict = Doc.extract_data()
        self.data_dict = self.doc.extract_tags()
        self.entry_count = len(self.data_dict.keys())
        if self.entry_count:
            print "Total Entries: ", self.entry_count
        else:
            sys.exit("\nNo matching entries found!")
        
    def print_data(self):
        """ To print entries """
        for entry_id in self.data_dict.keys():
            print "ID: %s" % (entry_id)
            pprint(self.data_dict[entry_id])
            print
        '''
        # if data type were XML
        for i in xrange(entry_count):
            print "Entry %d: "%(i+1),"\n"
            print self.data_xml[i].toxml()
            print "\n-----------------\n"
        '''

    def store_data(self):
        """ write response to enternal file """
        # write to JSON
        self.data_json = json.JSONEncoder().encode(self.data_dict)
        f_json = open( SOURCE_PATH + 'log/output/query_results.json','wb')
        f_json.write(self.data_json)
        f_json.close()
        # write to XML
        f_xml = open( SOURCE_PATH + 'log/output/query_results.xml','wb')
        f_xml.write(self.query_xml)
        f_xml.close()

    def generate_html(self):
        """ generates an html to read results 
        in the browser, in raw form."""
        html_code = """<html>
        <head>
        <title>ScholaRec produced the following search response</title>
        <h1>Results for keywords: %s</h1>
        </head>
        <body> """ % (self.keywords)
        html_code += '<pre>' + pformat(self.data_dict) + '</pre>'
        html_code += """</body></html>"""        
        # write HTML
        fo = open( SOURCE_PATH + 'log/output/results_simple.html', 'wb')
        fo.write(html_code)
        fo.close()
        # write results as a text file
        fo = open( SOURCE_PATH + 'log/output/results.txt', 'wb')
        fo.write( str(self.data_dict) )
        fo.close()

    def store_pdfs(self):
        """ retrieve and extract pdfs."""
        print "Now downloading all pdf's .. "
        self.doc.extract_pdfs()

if __name__ == '__main__':
    try:
        prefixes = { "ti" : "Title",
                     "au" : "Author",
                     "abs" : "Abstract",
                     "cat" : "Subject Category",
                     "all" : "All of the above"
                 }
        for i, prefix in enumerate(prefixes.values()):
            print i+1, prefix
        CHOICE = int(raw_input("Enter choice: ")) - 1
        assert 0 <= CHOICE <= len(prefixes)
        KEYWORDS = raw_input("\nEnter keywords, to query arXiv: ")
        START = int(raw_input("Enter pagination start (0,1,..): "))
        BASE_URL = "http://export.arxiv.org/api/query?"
        SEARCH_QUERY = prefixes.items()[CHOICE][0] + ":%22" \
                       + '%20'.join(KEYWORDS.split()) + "%22"
        MAX_RESULTS = int(raw_input("Enter maximum result count: "))
        SEARCH = BASE_URL + \
                 'search_query=%s&start=%i&max_results=%i' % \
                 (SEARCH_QUERY,
                  START,
                  MAX_RESULTS)        
        print "\n\t\tPlease wait for query response.."
        RESPONSE = urlopen(SEARCH)
        assert RESPONSE.msg.upper() == 'OK'        
        print "\t\tResponse: OK\n"

        XML_RESPONSE = RESPONSE.read()
        QP = QueryParse(XML_RESPONSE, KEYWORDS)
        QP.parse_data()

        CHOICE = raw_input("\nPrint entries? (y/n): ")
        if CHOICE.lower() == 'y':
            # print data
            QP.print_data()
            
        CHOICE = raw_input("\nStore response to log/output? (y/n): ")
        if CHOICE.lower() == 'y':
            # store data        
            QP.store_data()

        CHOICE = raw_input("\nExtract PDF's & plain texts? (y/n): ")
        if CHOICE.lower() == 'y':
            # retrieve pdfs & store them
            QP.store_pdfs()

        CHOICE = raw_input("\nGenerate HTML in log/output/? (y/n): ")
        if CHOICE.lower() == 'y':
            # retrieve pdfs & store them
            QP.generate_html()
        print "\nWikipedia says:"
        print "---------------\n"
        try:
            print wikipedia.summary(KEYWORDS, auto_suggest=False)
        except:
            topics = wikipedia.search(KEYWORDS)
            print "{} may refer to: ".format(KEYWORDS)
            for i, topic in enumerate(topics[1:]):
                print i+1, topic
            CHOICE = int(raw_input("Enter a choice: "))
            assert CHOICE in xrange(1,len(topics))
            print wikipedia.summary(topics[CHOICE], auto_suggest=False)
        print "\nYou've searched for : %s \n" % (KEYWORDS)
        print "\nEnter this URL in browser, for GUI mode: \n %s \n" % (SEARCH) 
        print "\n\t\tThanks for using ScholaRec!\n"
        
    except IOError as err:
        print "\nI/O error({0}): {1}".format(err.errno, err.strerror)
        print "OR 'Maybe' you're disconnect from the Internet.."
    except KeyboardInterrupt:
        print "\n\n\t\tYou've aborted the program! \n"
    except ValueError as err:
        print "\nERROR: ", err, "\nCheck your input type."
    except IndexError as err:
        print "\nERROR: ", err, "\nResponse attributes not satisfied."
    except AssertionError as err:
        print "\nERROR: Response: not OK! Maybe a site error"
    except:
        # >>sys.exc_info()<< gives whole exception
        print "Error: ", sys.exc_info()[0]  
        # system call to raise the exception out loud
        raise
